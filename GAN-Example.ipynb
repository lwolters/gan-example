{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Description Generation\n",
    "\n",
    "## Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib===3.3.2\n",
      "  Using cached matplotlib-3.3.2-cp38-cp38-manylinux1_x86_64.whl (11.6 MB)\n",
      "Requirement already satisfied: numpy==1.18.3 in ./gan-example-env/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.18.3)\n",
      "Requirement already satisfied: pandas==1.0.3 in ./gan-example-env/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.0.3)\n",
      "Requirement already satisfied: torch==1.5.0 in ./gan-example-env/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (1.5.0)\n",
      "Requirement already satisfied: torchvision==0.6.0 in ./gan-example-env/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (0.6.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./gan-example-env/lib/python3.8/site-packages (from matplotlib===3.3.2->-r requirements.txt (line 1)) (8.0.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in ./gan-example-env/lib/python3.8/site-packages (from matplotlib===3.3.2->-r requirements.txt (line 1)) (2.4.7)\n",
      "Collecting certifi>=2020.06.20\n",
      "  Using cached certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in ./gan-example-env/lib/python3.8/site-packages (from matplotlib===3.3.2->-r requirements.txt (line 1)) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.2.0-cp38-cp38-manylinux1_x86_64.whl (92 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./gan-example-env/lib/python3.8/site-packages (from pandas==1.0.3->-r requirements.txt (line 3)) (2020.1)\n",
      "Requirement already satisfied: future in ./gan-example-env/lib/python3.8/site-packages (from torch==1.5.0->-r requirements.txt (line 4)) (0.18.2)\n",
      "Requirement already satisfied: six in ./gan-example-env/lib/python3.8/site-packages (from cycler>=0.10->matplotlib===3.3.2->-r requirements.txt (line 1)) (1.15.0)\n",
      "Installing collected packages: certifi, cycler, kiwisolver, matplotlib\n",
      "Successfully installed certifi-2020.6.20 cycler-0.10.0 kiwisolver-1.2.0 matplotlib-3.3.2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib_is_available = True\n",
    "try:\n",
    "  from matplotlib import pyplot as plt\n",
    "except ImportError:\n",
    "  print(\"Will skip plotting; matplotlib is not available.\")\n",
    "  matplotlib_is_available = False\n",
    "\n",
    "# Data params\n",
    "data_mean = 4\n",
    "data_stddev = 1.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data [Only 4 moments]\n"
     ]
    }
   ],
   "source": [
    "# ### Uncomment only one of these to define what data is actually sent to the Discriminator\n",
    "#(name, preprocess, d_input_func) = (\"Raw data\", lambda data: data, lambda x: x)\n",
    "#(name, preprocess, d_input_func) = (\"Data and variances\", lambda data: decorate_with_diffs(data, 2.0), lambda x: x * 2)\n",
    "#(name, preprocess, d_input_func) = (\"Data and diffs\", lambda data: decorate_with_diffs(data, 1.0), lambda x: x * 2)\n",
    "(name, preprocess, d_input_func) = (\"Only 4 moments\", lambda data: get_moments(data), lambda x: 4)\n",
    "\n",
    "print(\"Using data [%s]\" % (name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_sampler(mu, sigma):\n",
    "    return lambda n: torch.Tensor(np.random.normal(mu, sigma, (1, n)))  # Gaussian\n",
    "\n",
    "def get_generator_input_sampler():\n",
    "    return lambda m, n: torch.rand(m, n)  # Uniform-dist data into generator, _NOT_ Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Generator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.map1(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map2(x)\n",
    "        x = self.f(x)\n",
    "        x = self.map3(x)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, f):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.map1 = nn.Linear(input_size, hidden_size)\n",
    "        self.map2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.map3 = nn.Linear(hidden_size, output_size)\n",
    "        self.f = f\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.f(self.map1(x))\n",
    "        x = self.f(self.map2(x))\n",
    "        return self.f(self.map3(x))\n",
    "    \n",
    "def extract(v):\n",
    "    return v.data.storage().tolist()\n",
    "\n",
    "def stats(d):\n",
    "    return [np.mean(d), np.std(d)]\n",
    "\n",
    "def get_moments(d):\n",
    "    # Return the first 4 moments of the data provided\n",
    "    mean = torch.mean(d)\n",
    "    diffs = d - mean\n",
    "    var = torch.mean(torch.pow(diffs, 2.0))\n",
    "    std = torch.pow(var, 0.5)\n",
    "    zscores = diffs / std\n",
    "    skews = torch.mean(torch.pow(zscores, 3.0))\n",
    "    kurtoses = torch.mean(torch.pow(zscores, 4.0)) - 3.0  # excess kurtosis, should be 0 for Gaussian\n",
    "    final = torch.cat((mean.reshape(1,), std.reshape(1,), skews.reshape(1,), kurtoses.reshape(1,)))\n",
    "    return final\n",
    "\n",
    "def decorate_with_diffs(data, exponent, remove_raw_data=False):\n",
    "    mean = torch.mean(data.data, 1, keepdim=True)\n",
    "    mean_broadcast = torch.mul(torch.ones(data.size()), mean.tolist()[0][0])\n",
    "    diffs = torch.pow(data - Variable(mean_broadcast), exponent)\n",
    "    if remove_raw_data:\n",
    "        return torch.cat([diffs], 1)\n",
    "    else:\n",
    "        return torch.cat([data, diffs], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Model parameters\n",
    "    g_input_size = 1      # Random noise dimension coming into generator, per output vector\n",
    "    g_hidden_size = 5     # Generator complexity\n",
    "    g_output_size = 1     # Size of generated output vector\n",
    "    d_input_size = 500    # Minibatch size - cardinality of distributions\n",
    "    d_hidden_size = 10    # Discriminator complexity\n",
    "    d_output_size = 1     # Single dimension for 'real' vs. 'fake' classification\n",
    "    minibatch_size = d_input_size\n",
    "\n",
    "    d_learning_rate = 1e-3\n",
    "    g_learning_rate = 1e-3\n",
    "    sgd_momentum = 0.9\n",
    "\n",
    "    num_epochs = 5000\n",
    "    print_interval = 100\n",
    "    d_steps = 20\n",
    "    g_steps = 20\n",
    "\n",
    "    dfe, dre, ge = 0, 0, 0\n",
    "    d_real_data, d_fake_data, g_fake_data = None, None, None\n",
    "\n",
    "    discriminator_activation_function = torch.sigmoid\n",
    "    generator_activation_function = torch.tanh\n",
    "\n",
    "    d_sampler = get_distribution_sampler(data_mean, data_stddev)\n",
    "    gi_sampler = get_generator_input_sampler()\n",
    "    G = Generator(input_size=g_input_size,\n",
    "                  hidden_size=g_hidden_size,\n",
    "                  output_size=g_output_size,\n",
    "                  f=generator_activation_function)\n",
    "    D = Discriminator(input_size=d_input_func(d_input_size),\n",
    "                      hidden_size=d_hidden_size,\n",
    "                      output_size=d_output_size,\n",
    "                      f=discriminator_activation_function)\n",
    "    criterion = nn.BCELoss()  # Binary cross entropy: http://pytorch.org/docs/nn.html#bceloss\n",
    "    d_optimizer = optim.SGD(D.parameters(), lr=d_learning_rate, momentum=sgd_momentum)\n",
    "    g_optimizer = optim.SGD(G.parameters(), lr=g_learning_rate, momentum=sgd_momentum)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for d_index in range(d_steps):\n",
    "            # 1. Train D on real+fake\n",
    "            D.zero_grad()\n",
    "\n",
    "            #  1A: Train D on real\n",
    "            d_real_data = Variable(d_sampler(d_input_size))\n",
    "            d_real_decision = D(preprocess(d_real_data))\n",
    "            d_real_error = criterion(d_real_decision, Variable(torch.ones([1,1])))  # ones = true\n",
    "            d_real_error.backward() # compute/store gradients, but don't change params\n",
    "\n",
    "            #  1B: Train D on fake\n",
    "            d_gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            d_fake_data = G(d_gen_input).detach()  # detach to avoid training G on these labels\n",
    "            d_fake_decision = D(preprocess(d_fake_data.t()))\n",
    "            d_fake_error = criterion(d_fake_decision, Variable(torch.zeros([1,1])))  # zeros = fake\n",
    "            d_fake_error.backward()\n",
    "            d_optimizer.step()     # Only optimizes D's parameters; changes based on stored gradients from backward()\n",
    "\n",
    "            dre, dfe = extract(d_real_error)[0], extract(d_fake_error)[0]\n",
    "\n",
    "        for g_index in range(g_steps):\n",
    "            # 2. Train G on D's response (but DO NOT train D on these labels)\n",
    "            G.zero_grad()\n",
    "\n",
    "            gen_input = Variable(gi_sampler(minibatch_size, g_input_size))\n",
    "            g_fake_data = G(gen_input)\n",
    "            dg_fake_decision = D(preprocess(g_fake_data.t()))\n",
    "            g_error = criterion(dg_fake_decision, Variable(torch.ones([1,1])))  # Train G to pretend it's genuine\n",
    "\n",
    "            g_error.backward()\n",
    "            g_optimizer.step()  # Only optimizes G's parameters\n",
    "            ge = extract(g_error)[0]\n",
    "\n",
    "        if epoch % print_interval == 0:\n",
    "            print(\"Epoch %s: D (%s real_err, %s fake_err) G (%s err); Real Dist (%s),  Fake Dist (%s) \" %\n",
    "                  (epoch, dre, dfe, ge, stats(extract(d_real_data)), stats(extract(d_fake_data))))\n",
    "\n",
    "    if matplotlib_is_available:\n",
    "        print(\"Plotting the generated distribution...\")\n",
    "        values = extract(g_fake_data)\n",
    "        print(\" Values: %s\" % (str(values)))\n",
    "        plt.hist(values, bins=50)\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Count')\n",
    "        plt.title('Histogram of Generated Distribution')\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonard/Workspace/ai/gan-example/gan-example-env/lib/python3.8/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D (0.6356237530708313 real_err, 0.7457542419433594 fake_err) G (0.6436469554901123 err); Real Dist ([4.097293556138873, 1.3608997742610422]),  Fake Dist ([-0.26511934959888456, 0.00287179412706117]) \n",
      "Epoch 100: D (0.38277196884155273 real_err, 0.38550567626953125 fake_err) G (1.1090707778930664 err); Real Dist ([4.012139488995075, 1.2652739553653076]),  Fake Dist ([6.3833117618560795, 0.024387508731657303]) \n",
      "Epoch 200: D (0.804203450679779 real_err, 0.651988685131073 fake_err) G (0.6777949929237366 err); Real Dist ([3.9327941635251045, 1.2453464088484818]),  Fake Dist ([5.797787687182426, 2.373885405064121]) \n",
      "Epoch 300: D (0.7125104665756226 real_err, 0.6992738246917725 fake_err) G (0.6834885478019714 err); Real Dist ([3.9833833258748053, 1.2628161802604523]),  Fake Dist ([3.7294673819541933, 1.9896248352751682]) \n",
      "Epoch 400: D (0.6950849294662476 real_err, 0.6967185139656067 fake_err) G (0.6893845200538635 err); Real Dist ([4.008415797114372, 1.2440061054313922]),  Fake Dist ([6.11994412612915, 2.367337818442559]) \n",
      "Epoch 500: D (0.6850454807281494 real_err, 0.677534282207489 fake_err) G (0.709865927696228 err); Real Dist ([4.045827741533518, 1.2709199155140098]),  Fake Dist ([5.506725037097931, 1.9960648681285569]) \n",
      "Epoch 600: D (0.6324945092201233 real_err, 0.6304114460945129 fake_err) G (0.7605690956115723 err); Real Dist ([3.9428469584584236, 1.216808664877104]),  Fake Dist ([8.181959692955017, 0.8880375502315392]) \n",
      "Epoch 700: D (0.7588858604431152 real_err, 0.5820710062980652 fake_err) G (0.7232078909873962 err); Real Dist ([4.119859648287297, 1.240237629446699]),  Fake Dist ([6.772625692367554, 0.7878362527731209]) \n",
      "Epoch 800: D (0.7625274062156677 real_err, 0.6763330101966858 fake_err) G (0.662476658821106 err); Real Dist ([4.0439104467183355, 1.2908458902399742]),  Fake Dist ([4.506245763778686, 0.3712698796329552]) \n",
      "Epoch 900: D (0.7186946868896484 real_err, 0.7176440358161926 fake_err) G (0.6655750274658203 err); Real Dist ([4.012375678002834, 1.2100857251221562]),  Fake Dist ([4.955772871494293, 2.4218418855006667]) \n",
      "Epoch 1000: D (0.6940762400627136 real_err, 0.6929726600646973 fake_err) G (0.6910420060157776 err); Real Dist ([4.006027210175991, 1.2355458360067313]),  Fake Dist ([4.6649040477275845, 1.4892173058916338]) \n",
      "Epoch 1100: D (0.6392017006874084 real_err, 0.8916482329368591 fake_err) G (0.45806941390037537 err); Real Dist ([4.043030487746, 1.2360426749491862]),  Fake Dist ([3.8363064641952516, 0.5468400104309775]) \n",
      "Epoch 1200: D (0.6979334354400635 real_err, 0.6995148062705994 fake_err) G (0.6866017580032349 err); Real Dist ([4.01678850671649, 1.2380481017096145]),  Fake Dist ([5.979344964981079, 0.4049987284764286]) \n",
      "Epoch 1300: D (0.6976851224899292 real_err, 0.6969568729400635 fake_err) G (0.6892054080963135 err); Real Dist ([3.9471119129192083, 1.236943088208583]),  Fake Dist ([6.28766098022461, 0.4625431212617829]) \n",
      "Epoch 1400: D (0.697417676448822 real_err, 0.6964170932769775 fake_err) G (0.6897136569023132 err); Real Dist ([3.955007280111313, 1.1986366968091962]),  Fake Dist ([6.416790303230286, 0.4789570643494934]) \n",
      "Epoch 1500: D (0.6955074071884155 real_err, 0.695743203163147 fake_err) G (0.6905684471130371 err); Real Dist ([3.9944300784170625, 1.261114643093115]),  Fake Dist ([6.5418253421783445, 0.528245168227032]) \n",
      "Epoch 1600: D (0.694697380065918 real_err, 0.6953102946281433 fake_err) G (0.6910074949264526 err); Real Dist ([4.0258364863395695, 1.275274025854799]),  Fake Dist ([6.623656936645508, 0.5806662249052899]) \n",
      "Epoch 1700: D (0.6949782371520996 real_err, 0.6950585246086121 fake_err) G (0.6913137435913086 err); Real Dist ([3.9452607518434526, 1.1456399981850878]),  Fake Dist ([6.69366104221344, 0.5897394368985032]) \n",
      "Epoch 1800: D (0.6949548721313477 real_err, 0.6947762966156006 fake_err) G (0.6915355920791626 err); Real Dist ([3.948154050052166, 1.2123589694964787]),  Fake Dist ([6.690435858726501, 0.5678746183544093]) \n",
      "Epoch 1900: D (0.6947032809257507 real_err, 0.6946501135826111 fake_err) G (0.6916601061820984 err); Real Dist ([4.033948713064194, 1.2584699221038458]),  Fake Dist ([6.720987545013427, 0.589312620777411]) \n",
      "Epoch 2000: D (0.6944090127944946 real_err, 0.6945026516914368 fake_err) G (0.6918050646781921 err); Real Dist ([3.9273373522758486, 1.2261562084816937]),  Fake Dist ([6.750885845184326, 0.6040510452205471]) \n",
      "Epoch 2100: D (0.6938861608505249 real_err, 0.6943646669387817 fake_err) G (0.6919237971305847 err); Real Dist ([4.073433992862701, 1.1943405846909396]),  Fake Dist ([6.730980900764465, 0.6231702573583252]) \n",
      "Epoch 2200: D (0.6938292980194092 real_err, 0.6942353248596191 fake_err) G (0.6920677423477173 err); Real Dist ([4.132208598017693, 1.2887734167638192]),  Fake Dist ([6.77477903842926, 0.6062283609507526]) \n",
      "Epoch 2300: D (0.6940181851387024 real_err, 0.6941846013069153 fake_err) G (0.6921152472496033 err); Real Dist ([3.9832598558664323, 1.2118234808318245]),  Fake Dist ([6.782528568267822, 0.6421106775792575]) \n",
      "Epoch 2400: D (0.6937229037284851 real_err, 0.6941180229187012 fake_err) G (0.6921921968460083 err); Real Dist ([4.1041453805565835, 1.2720029849513514]),  Fake Dist ([6.857043435096741, 0.6510362695129405]) \n",
      "Epoch 2500: D (0.6940358877182007 real_err, 0.6940335631370544 fake_err) G (0.6922648549079895 err); Real Dist ([4.021301571965218, 1.1728769290378303]),  Fake Dist ([6.819596497535706, 0.6623114578029805]) \n",
      "Epoch 2600: D (0.6942747831344604 real_err, 0.6939905881881714 fake_err) G (0.6923147439956665 err); Real Dist ([3.8814576729536054, 1.2801166500634082]),  Fake Dist ([6.835465908050537, 0.6315584294069494]) \n",
      "Epoch 2700: D (0.6935548782348633 real_err, 0.693904459476471 fake_err) G (0.69239741563797 err); Real Dist ([4.09132167673111, 1.202747817591662]),  Fake Dist ([6.85294651222229, 0.6095458940351798]) \n",
      "Epoch 2800: D (0.693985104560852 real_err, 0.6938579082489014 fake_err) G (0.6924412250518799 err); Real Dist ([3.9911974627673628, 1.299144013091732]),  Fake Dist ([6.879909683227539, 0.6558466134000935]) \n",
      "Epoch 2900: D (0.6933898329734802 real_err, 0.6938328742980957 fake_err) G (0.6924573183059692 err); Real Dist ([4.114993668034673, 1.2828851208719876]),  Fake Dist ([6.888987115859985, 0.6440113564101257]) \n",
      "Epoch 3000: D (0.6935709714889526 real_err, 0.6938046216964722 fake_err) G (0.692493200302124 err); Real Dist ([4.069244860649109, 1.2319268184307348]),  Fake Dist ([6.855734647750855, 0.6869642545335097]) \n",
      "Epoch 3100: D (0.6935715675354004 real_err, 0.6937598586082458 fake_err) G (0.6925411820411682 err); Real Dist ([4.065195370197296, 1.2135147851289114]),  Fake Dist ([6.91071597290039, 0.6456671749745431]) \n",
      "Epoch 3200: D (0.6933799386024475 real_err, 0.6937461495399475 fake_err) G (0.6925435662269592 err); Real Dist ([4.119615424156189, 1.2048315366852909]),  Fake Dist ([6.814331663131714, 0.6059718490826549]) \n",
      "Epoch 3300: D (0.6936812996864319 real_err, 0.6936922073364258 fake_err) G (0.6926050186157227 err); Real Dist ([4.026271575649269, 1.2164794214075318]),  Fake Dist ([6.851396414756775, 0.6530875045843468]) \n",
      "Epoch 3400: D (0.6935628652572632 real_err, 0.6936779022216797 fake_err) G (0.6926158666610718 err); Real Dist ([3.9580109142512083, 1.2792485217351997]),  Fake Dist ([6.906865725517273, 0.6554978427894168]) \n",
      "Epoch 3500: D (0.6934154033660889 real_err, 0.693649172782898 fake_err) G (0.692639946937561 err); Real Dist ([4.073157366171479, 1.296880762608413]),  Fake Dist ([6.867094903945923, 0.660118438456125]) \n",
      "Epoch 3600: D (0.6934725642204285 real_err, 0.6936159133911133 fake_err) G (0.6926764249801636 err); Real Dist ([3.9805876333266497, 1.267980960060553]),  Fake Dist ([6.875397637367248, 0.6309930334993675]) \n",
      "Epoch 3700: D (0.693616509437561 real_err, 0.6936079263687134 fake_err) G (0.6926841735839844 err); Real Dist ([3.9898908619880675, 1.1863119571785161]),  Fake Dist ([6.880413681030274, 0.6630365697716024]) \n",
      "Epoch 3800: D (0.6934062242507935 real_err, 0.6936068534851074 fake_err) G (0.6926888227462769 err); Real Dist ([4.073168681114912, 1.266286715209929]),  Fake Dist ([6.942680182456971, 0.6343024418481387]) \n",
      "Epoch 3900: D (0.6935546398162842 real_err, 0.6935713887214661 fake_err) G (0.6927221417427063 err); Real Dist ([3.957521800041199, 1.2704548801281714]),  Fake Dist ([6.922373296737671, 0.6286209330693489]) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000: D (0.6935822367668152 real_err, 0.6935535073280334 fake_err) G (0.6927391886711121 err); Real Dist ([3.9427191668748858, 1.2390430581914194]),  Fake Dist ([6.8668814554214475, 0.6402766202510479]) \n",
      "Epoch 4100: D (0.6934506297111511 real_err, 0.6935425400733948 fake_err) G (0.6927523016929626 err); Real Dist ([3.9318987146615982, 1.279211874193192]),  Fake Dist ([6.904089312553406, 0.6705021695637622]) \n",
      "Epoch 4200: D (0.693457305431366 real_err, 0.6935186982154846 fake_err) G (0.6927786469459534 err); Real Dist ([3.9807126039266585, 1.2844967712273354]),  Fake Dist ([6.962624062538147, 0.7017590818787743]) \n",
      "Epoch 4300: D (0.6934190988540649 real_err, 0.6935052275657654 fake_err) G (0.6927909255027771 err); Real Dist ([3.9319404734373093, 1.298327987966256]),  Fake Dist ([6.953814260482788, 0.6720651623256297]) \n",
      "Epoch 4400: D (0.6933931708335876 real_err, 0.6934933066368103 fake_err) G (0.6927995085716248 err); Real Dist ([3.9570751308202743, 1.323941686140453]),  Fake Dist ([6.941342535018921, 0.6606231356612886]) \n",
      "Epoch 4500: D (0.6934675574302673 real_err, 0.6934767365455627 fake_err) G (0.6928184628486633 err); Real Dist ([4.00409183417866, 1.2919640654644788]),  Fake Dist ([6.932343279838562, 0.6684340955864214]) \n",
      "Epoch 4600: D (0.693312406539917 real_err, 0.6934673190116882 fake_err) G (0.6928269267082214 err); Real Dist ([4.112246731638908, 1.22537958994732]),  Fake Dist ([6.886791857719421, 0.6960225834785493]) \n",
      "Epoch 4700: D (0.693389356136322 real_err, 0.6934433579444885 fake_err) G (0.6928500533103943 err); Real Dist ([3.9169431524276734, 1.2666365322553244]),  Fake Dist ([6.945333076477051, 0.6712979772907813]) \n",
      "Epoch 4800: D (0.6934263706207275 real_err, 0.6934352517127991 fake_err) G (0.6928601861000061 err); Real Dist ([3.9494578431248666, 1.2475147408128497]),  Fake Dist ([6.927382008552551, 0.6861831354878997]) \n",
      "Epoch 4900: D (0.6933183670043945 real_err, 0.6934219002723694 fake_err) G (0.6928710341453552 err); Real Dist ([3.9992108497619627, 1.2704774659387648]),  Fake Dist ([6.922661526679993, 0.6425565061091758]) \n",
      "Plotting the generated distribution...\n",
      " Values: [5.770916938781738, 7.224661827087402, 7.00703763961792, 7.257124900817871, 7.201663970947266, 6.776243209838867, 5.902320861816406, 6.4291582107543945, 6.372400283813477, 7.358162879943848, 5.991910934448242, 6.911442756652832, 6.442523002624512, 6.636732578277588, 6.50131893157959, 6.082588195800781, 7.210238456726074, 6.94265079498291, 6.388625144958496, 7.842202186584473, 6.898975849151611, 6.917845726013184, 6.930690288543701, 6.650555610656738, 7.161193370819092, 8.65517520904541, 6.161246299743652, 5.795377731323242, 6.9787211418151855, 8.7485933303833, 5.999931335449219, 6.853536605834961, 7.01165246963501, 6.9328765869140625, 6.781641006469727, 7.2590436935424805, 6.707906723022461, 7.219195365905762, 7.593700408935547, 6.973668098449707, 5.933065414428711, 5.734753608703613, 7.525668144226074, 7.082788467407227, 6.235283851623535, 6.9899139404296875, 6.702026844024658, 7.022513389587402, 5.882477760314941, 6.526944160461426, 7.432936668395996, 6.843967437744141, 5.745241165161133, 8.847091674804688, 7.042201042175293, 7.136264324188232, 6.28802490234375, 5.761349678039551, 6.876354217529297, 8.335412979125977, 6.631565093994141, 7.3402557373046875, 7.094555377960205, 7.391812801361084, 7.120444297790527, 8.876813888549805, 6.679750442504883, 6.747088432312012, 6.21881103515625, 7.574122428894043, 8.477335929870605, 7.950631141662598, 6.143151760101318, 8.537561416625977, 7.139562606811523, 7.740009307861328, 7.360304832458496, 6.092478275299072, 6.340938568115234, 6.968837738037109, 7.484652519226074, 7.457460403442383, 8.792123794555664, 5.8308610916137695, 8.372420310974121, 6.906639099121094, 7.176391124725342, 7.198870658874512, 7.352259635925293, 7.309145927429199, 7.207082748413086, 7.377486705780029, 7.175931930541992, 6.29499626159668, 6.975944995880127, 6.711889266967773, 7.235911846160889, 7.455763816833496, 8.223230361938477, 9.020271301269531, 6.515841484069824, 6.66093635559082, 7.108355522155762, 6.665848731994629, 7.39070987701416, 5.882283687591553, 6.7490763664245605, 6.003239631652832, 6.883988380432129, 6.861250877380371, 6.445596218109131, 5.901298522949219, 6.664434432983398, 7.128350257873535, 8.245079040527344, 8.421662330627441, 6.666922092437744, 7.318333625793457, 7.6331939697265625, 5.866392135620117, 6.968290328979492, 5.948916435241699, 6.801336288452148, 6.952325820922852, 6.681553840637207, 8.069540023803711, 6.961859226226807, 6.8303608894348145, 6.110929012298584, 6.333637237548828, 6.540010452270508, 7.189516067504883, 7.046995162963867, 6.089266777038574, 7.132944107055664, 6.790106773376465, 6.995383262634277, 7.6541948318481445, 6.1971940994262695, 6.721869468688965, 7.91667366027832, 7.963028907775879, 8.148719787597656, 7.123859882354736, 7.057121276855469, 6.8506388664245605, 6.566353797912598, 8.09597396850586, 7.1993913650512695, 6.779670715332031, 7.1710710525512695, 5.917433738708496, 7.398618698120117, 7.383371353149414, 6.629157066345215, 6.362712860107422, 8.999167442321777, 8.333897590637207, 6.251522064208984, 7.051009654998779, 7.972002029418945, 5.959564208984375, 6.868706226348877, 7.273453235626221, 7.249486923217773, 8.794814109802246, 7.219878673553467, 7.635422706604004, 6.7660603523254395, 7.187770843505859, 7.235596656799316, 7.308380603790283, 8.27351188659668, 6.569733619689941, 6.370161056518555, 6.186990737915039, 6.393572807312012, 6.415229320526123, 6.796908378601074, 7.283779144287109, 8.198731422424316, 6.933300018310547, 6.185044288635254, 6.926918029785156, 7.028112411499023, 8.303834915161133, 5.775474548339844, 6.741114616394043, 7.2258100509643555, 6.970681190490723, 6.909083843231201, 7.242498397827148, 6.541810035705566, 7.895893096923828, 6.88142204284668, 7.037474632263184, 6.088715076446533, 6.544768333435059, 7.152873992919922, 6.888517379760742, 7.434109687805176, 6.426839828491211, 6.965198040008545, 7.499594688415527, 7.3813300132751465, 7.543328285217285, 6.707225799560547, 6.171407699584961, 6.458093643188477, 7.298760414123535, 6.289433479309082, 6.673078536987305, 7.312646865844727, 7.507942199707031, 7.06217622756958, 7.16475772857666, 7.511262893676758, 7.16099214553833, 7.236453056335449, 7.369017601013184, 6.92655086517334, 7.235754013061523, 6.530029296875, 7.064735412597656, 8.40598201751709, 5.7178168296813965, 6.87376594543457, 8.035059928894043, 7.081042766571045, 6.686872959136963, 7.312892913818359, 7.112665176391602, 8.486632347106934, 6.389215469360352, 6.540063858032227, 6.632290840148926, 6.382716178894043, 7.176430702209473, 7.0788116455078125, 6.520428657531738, 6.77667236328125, 7.331921100616455, 6.4978837966918945, 7.290536403656006, 7.08803653717041, 6.410552978515625, 6.75112247467041, 7.243927955627441, 6.895704746246338, 5.899988174438477, 5.721779823303223, 7.142858505249023, 7.266380310058594, 5.740324020385742, 6.566828727722168, 6.92799186706543, 6.835498332977295, 7.203261375427246, 6.890651702880859, 6.738725662231445, 7.250914096832275, 7.657489776611328, 5.835963249206543, 7.085346221923828, 7.283332824707031, 6.858508110046387, 6.451624870300293, 7.137791633605957, 6.6805009841918945, 7.255921363830566, 8.30215835571289, 5.887514114379883, 6.986207962036133, 7.0714192390441895, 6.064408302307129, 6.0259928703308105, 7.119254112243652, 6.905936241149902, 6.952948570251465, 6.641407489776611, 6.235565185546875, 7.176338195800781, 6.926923751831055, 7.1101837158203125, 5.922825813293457, 6.7138214111328125, 6.310275077819824, 8.175359725952148, 7.028301239013672, 6.006217956542969, 8.395040512084961, 6.408164024353027, 7.016996383666992, 7.2487382888793945, 7.031173229217529, 6.302720069885254, 5.940468788146973, 7.768664360046387, 7.137648582458496, 6.006032943725586, 6.8037824630737305, 8.636582374572754, 6.979250907897949, 8.11730670928955, 7.8082733154296875, 7.171411037445068, 6.1106367111206055, 5.8877854347229, 6.203317642211914, 6.740372657775879, 6.256972312927246, 7.257521152496338, 7.047488212585449, 5.73731803894043, 7.752309799194336, 6.684606075286865, 7.227963447570801, 5.88955020904541, 6.649076461791992, 7.295849323272705, 7.0077128410339355, 7.052079200744629, 7.11967658996582, 6.546040058135986, 6.039560317993164, 7.157236099243164, 6.665532112121582, 7.25788688659668, 7.436928749084473, 8.318103790283203, 7.308296203613281, 8.724626541137695, 7.192726135253906, 8.875612258911133, 6.859177589416504, 6.966409206390381, 7.164718151092529, 7.888598442077637, 7.1984124183654785, 7.578296661376953, 5.93403434753418, 6.815418243408203, 6.505913734436035, 7.993934631347656, 7.12342643737793, 7.341748237609863, 8.219785690307617, 7.224011421203613, 5.949544906616211, 6.675027847290039, 7.126761436462402, 8.050945281982422, 6.298131942749023, 6.649663925170898, 6.939209461212158, 7.08831262588501, 5.723028182983398, 6.51167631149292, 7.096454620361328, 6.659730911254883, 6.251962184906006, 6.138986587524414, 6.872968673706055, 7.897551536560059, 5.855291366577148, 5.877971649169922, 6.570005893707275, 6.150446891784668, 7.478423118591309, 7.062404155731201, 7.451663017272949, 7.100250720977783, 8.192258834838867, 6.364996910095215, 6.8468523025512695, 7.235342025756836, 7.223614692687988, 7.043758392333984, 7.051572322845459, 7.233593940734863, 6.1524810791015625, 6.661802291870117, 6.242984771728516, 7.753814697265625, 5.718157768249512, 6.8553338050842285, 6.771695613861084, 6.1749186515808105, 7.224664211273193, 8.055383682250977, 7.3669352531433105, 7.238927841186523, 6.439696311950684, 6.996460914611816, 5.940820693969727, 5.867347717285156, 7.2283220291137695, 7.101062297821045, 7.1151533126831055, 6.071211814880371, 6.982925891876221, 7.163020133972168, 6.350224494934082, 7.180631637573242, 7.450553894042969, 6.553323745727539, 7.291268348693848, 7.3655242919921875, 7.055384635925293, 5.87052059173584, 8.505273818969727, 7.081282138824463, 7.685331344604492, 7.212930679321289, 6.860983848571777, 7.1910529136657715, 7.026457786560059, 6.319830894470215, 6.369987487792969, 7.114524841308594, 5.789548873901367, 6.377127647399902, 6.697845935821533, 6.689176082611084, 6.86824369430542, 6.545271873474121, 7.084712028503418, 7.131597518920898, 6.871219635009766, 8.842595100402832, 5.87999153137207, 5.812911510467529, 7.190130233764648, 6.6137189865112305, 6.525437355041504, 6.361645698547363, 6.026721477508545, 8.009759902954102, 7.05441951751709, 6.500151634216309, 7.157088756561279, 7.0930705070495605, 7.181365489959717, 6.882819652557373, 5.8259687423706055, 6.594458103179932, 7.02789306640625, 7.111087322235107, 8.258131980895996, 7.561020851135254, 7.166823863983154, 5.74513053894043, 6.037261009216309, 8.049426078796387, 7.275353908538818, 6.792318344116211, 7.063316345214844, 7.0687127113342285, 7.097258567810059, 7.945364952087402, 7.190372943878174, 6.828569412231445, 6.986873626708984, 6.301129341125488, 8.364042282104492, 6.410044193267822, 6.401734828948975, 6.547049522399902, 6.2993879318237305, 7.319830417633057, 6.315021514892578, 6.785487651824951, 6.576170444488525, 6.313150405883789, 8.83695125579834, 7.782807350158691, 6.231227874755859, 7.330808639526367, 6.990317344665527, 6.931674003601074, 6.593358039855957, 7.096548080444336, 6.955558776855469, 6.71309757232666, 7.486778259277344, 6.59326171875, 8.070074081420898, 7.1605224609375, 6.580852031707764, 7.109356880187988, 6.060722351074219, 7.065925598144531, 7.2597479820251465, 6.805290222167969, 6.875860691070557, 5.94484806060791, 7.92854118347168, 6.699577331542969, 6.768808364868164, 7.024957656860352]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan-example-env",
   "language": "python",
   "name": "gan-example-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
